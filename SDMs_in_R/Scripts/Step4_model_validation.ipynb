{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "setwd(paste0(direct,folder))\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(raster)\n",
                "require(rgdal)\n",
                "\n",
                "direct<- \"/Users/s2992269/Documents/Use_cases\"\n",
                "folder <- \"/SDM_in_R\"\n",
                "\n",
                "#this sets your working director for all subsequent chunks of code in your R Markdown script\n",
                "knitr::opts_knit$set(root.dir = paste0(direct,folder))\n",
                "\n",
                "# if you are not working R Markdown, simply use this instead\n",
                "setwd(paste0(direct,folder))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# step 4 evaluate the model\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(caret)\n",
                "library(dismo)\n",
                "library(gbm)\n",
                "library(raster)\n",
                "library(sp)\n",
                "library(jpeg)\n",
                "library(galah)\n",
                "library(tidyr)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "setwd(paste0(direct,folder))\n",
                "getwd()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "setwd(\"~/Documents/Use_cases/SDM_in_R/predictors\")\n",
                "rast_lst <- list.files(pattern='.asc$', all.files=TRUE)\n",
                "rast_lst\n",
                "LiPe_predictors <- stack(rast_lst)\n",
                "crs(LiPe_predictors) <- \"+proj=longlat +datum=WGS84 +no_defs\"\n",
                "LiPe_predictors \n",
                "setwd(paste0(direct,folder))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "LiPe_thinned <- read.csv(\"data/LiPe_thinned.csv\", stringsAsFactors = FALSE)\n",
                "base <- raster(\"data/base_LiPe.asc\")\n",
                "crs(base) <- \"+proj=longlat +datum=WGS84 +no_defs\"\n",
                "\n",
                "x_LiPe<- LiPe_thinned$decimalLongitude\n",
                "y_LiPe<-LiPe_thinned$decimalLatitude\n",
                "xy_LiPe<-cbind(x_LiPe,y_LiPe)\n",
                "xy.sp_LiPe<-SpatialPoints(xy_LiPe)\n",
                "crs(xy.sp_LiPe) <- crs(base)\n",
                "crs(xy.sp_LiPe)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "LiPe_zero_3vis<-read.csv(\"data/LiPe_zero_locations_3vis.csv\")\n",
                "head(LiPe_zero_3vis)\n",
                "LiPe_zero_3vis$X <- NULL\n",
                "LiPe_zero_3vis$spp <- NULL\n",
                "head(LiPe_zero_3vis)\n",
                "LiPe_thin <- as.data.frame(cbind(Long = LiPe_thinned$decimalLongitude, Lat = LiPe_thinned$decimalLatitude, pres = LiPe_thinned$layer))\n",
                "LiPe_thin2 <- LiPe_thin[complete.cases(LiPe_thin), ]\n",
                "head(LiPe_thin2)\n",
                "LiPe_p_a <- rbind(LiPe_zero_3vis,LiPe_thin2)\n",
                "\n",
                "x_pa<- LiPe_p_a$Long\n",
                "y_pa<-LiPe_p_a$Lat\n",
                "xy_pa<-cbind(x_pa,y_pa)\n",
                "xy.sp_pa<-SpatialPoints(xy_pa)\n",
                "crs(xy.sp_pa) <- crs(LiPe_predictors)\n",
                "crs(xy.sp_pa)\n",
                "\n",
                "LiPe_preds <- raster::extract(LiPe_predictors,xy.sp_pa)\n",
                "LiPe_preds2 <- cbind(LiPe_p_a,LiPe_preds)\n",
                "LiPe_preds3 <- as.data.frame(LiPe_preds2[complete.cases(LiPe_preds2), ])\n",
                "summary(LiPe_preds3)\n",
                "names(LiPe_preds3) # note in gbm.step you specify the column index location, so pres is indexed as 3 in names\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# There are many ways to evaluate your model.  With statistical models you can evaluate residual plots to check that your model meets assumptions.\n",
                "#\n",
                "## It is often a good idea to break your data into randomly selected training and testing data.  Often you would randomly remove 20% or more of \n",
                "# your data and withold that from the model building process.  Once your model was finsihed using your training data, you would then test your \n",
                "# model with this training data. If you have very little data, bootstrapping can be used to see if removal of a small percentage of data repeatedly \n",
                "# changes results.  This gives you a good understanding of the confidence intervals around your results and can reduce the impact of outliers on your \n",
                "# inal result.  Cross-validation requires more data.  I deally for cross-validation you break your data into 10 folds (subsets) and compare results between \n",
                "# folds, or summarise variability between folds.  If you can afford to set aside 20% + of your data, withholding a test data set \n",
                "# is good practice.  Ideally, you will test your model with completely independent data.\n",
                "\n",
                "# here we evaluate the BRT model with the training data used to construct the model\n",
                "\n",
                "# First we run the BRT model again without additional variables identified in our simplify function\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "LiPe_mod_new <- gbm.step(data = LiPe_preds3, gbm.x = c(4:7), gbm.y = 3, family = \"bernoulli\", tree.complexity = 3, learning.rate = 0.01, bag.fraction = 0.75)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "LiPe_1s <- LiPe_preds3[LiPe_preds3$pres==1,]\n",
                "x_1s<- LiPe_1s$Long\n",
                "y_1s<-LiPe_1s$Lat\n",
                "xy_1s<-cbind(x_1s,y_1s)\n",
                "xy.sp_1s<-SpatialPoints(xy_1s)\n",
                "crs(xy.sp_1s) <- crs(LiPe_predictors)\n",
                "crs(xy.sp_1s)\n",
                "\n",
                "LiPe_0s <- LiPe_preds3[LiPe_preds3$pres==0,]\n",
                "x_0s<- LiPe_0s$Long\n",
                "y_0s<-LiPe_0s$Lat\n",
                "xy_0s<-cbind(x_0s,y_0s)\n",
                "xy.sp_0s<-SpatialPoints(xy_0s)\n",
                "crs(xy.sp_0s) <- crs(LiPe_predictors)\n",
                "crs(xy.sp_0s)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# look at which predictors are in our predictors stack\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "names(LiPe_predictors)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Here we drop the variables that were dropped from the LiPe_mod_new BRT model\n",
                "# This is so we can predict all locations using the subset of variables used in the model\n",
                "# In any model, the variables you use, need to match the variables you use to predict\n",
                "# column names, or raster stack names need to match exactly\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "LiPe_preds_brt_new <- LiPe_predictors[[which(c(TRUE,TRUE,TRUE,TRUE,FALSE,FALSE))]]\n",
                "\n",
                "brt_pred <- predict(LiPe_preds_brt_new,LiPe_mod_new,type=\"link\") # note we usually use type link, but the evaluate function is based on the \"link\" scale\n",
                "\n",
                "brt_eval_training <- dismo::evaluate(xy.sp_1s, xy.sp_0s, LiPe_mod_new, LiPe_preds_brt_new)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#There are a variety of ways to calculate a threshold, maximising \"kappa\" is one well supported method, but there are many others  \n",
                "# in Maxent we saw a table with a variety of ways to calculate thresholds\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "thresh_brt <- threshold(brt_eval_training,stat = \"kappa\")\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# another approach to thresholding - there are many choose the one that best fits in your model\n",
                "# thresh_brt2 <- threshold(brt_eval_training,stat = \"spec_sens\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "m <- c(-5, thresh_brt, 0,  thresh_brt, 2.1, 1)\n",
                "reclass <- matrix(m, ncol= 3, byrow= TRUE)\n",
                "rc_brt <- reclassify(brt_pred, reclass)\n",
                "\n",
                "plot(rc_brt)\n",
                "points(xy.sp_LiPe,pch=20,cex=0.2)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# look at training evaluation\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "brt_eval_training\n",
                "\n",
                "x_s<- LiPe_preds3$Long\n",
                "y_s<-LiPe_preds3$Lat\n",
                "xy_s<-cbind(x_s,y_s)\n",
                "xy.sp_s<-SpatialPoints(xy_s)\n",
                "crs(xy.sp_s) <- crs(LiPe_predictors)\n",
                "\n",
                "predicted <- raster::extract(rc_brt,xy.sp_s)\n",
                "\n",
                "test1 <- as.data.frame(cbind(predicted = predicted, reference = LiPe_preds3$pres))\n",
                "\n",
                "test1$reference <- factor(test1$reference, levels = c(\"1\",\"0\"))\n",
                "test1$predicted <- factor(test1$predicted, levels = c(\"1\",\"0\"))\n",
                "\n",
                "conf_matrix <- confusionMatrix(test1$predicted,test1$reference)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# this gives us the confusion matrix\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "conf_matrix$table\n",
                "\n",
                "TP <- conf_matrix$table[1,1]\n",
                "FP <- conf_matrix$table[1,2]\n",
                "FN <- conf_matrix$table[2,1]\n",
                "TN <- conf_matrix$table[2,2]\n",
                "\n",
                "FPR <- FP/(FP + TN)\n",
                "FNR <- FN/(FN + TP)\n",
                "TPR <- TP/(TP + FN)\n",
                "TNR <- TN/(TN + FP)\n",
                "\n",
                "TSS <- TPR + TNR - 1  # if we were predicting perfectly our TSS would = 1\n",
                "TSS # we are far from perfect in this model, and a much lower number that AUC\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# a perfect AUC value would also be 1\n",
                "# TSS often gives a better indication of prediction because it takes into\n",
                "# account anbalanced errors between positives and negatives\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Precision <- TP / (TP + FP)\n",
                "Recall <- TP / (TP + FN)\n",
                "F1 <- (2*Precision*Recall)/(Precision+Recall)#  F1 is another statistic, now thought to be\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# better than TSS\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "F1 <- TP /(TP + 0.5*(FP + FN)) # this is another way to calculate the same value\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# but the literature refers to Precision and Recall above (same thing though)\n",
                "# again perfect score would be 1\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "F1 # as you can see in our case F1 falls between AUC and TSS scores\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# now we are going to test our results from ALA records that were not from the FrogID project\n",
                "# for the most part we are just repeating code from step1\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "galah_config(email = \"r.clemens@griffith.edu.au\")\n",
                "\n",
                "LiPe_ALA<-galah_call() %>%\n",
                "  galah_identify(\"Limnodynastes peroni\")%>%\n",
                "  galah_filter(datasetName != \"FrogID\")%>%\n",
                "  galah_filter(coordinateUncertaintyInMeters < 200)%>%\n",
                "  galah_filter(year>1999)%>%\n",
                "  galah_filter(stateProvince == \"Queensland\")%>%\n",
                "  galah_select(\"datasetName\",\"year\")%>%\n",
                "  atlas_occurrences()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "LiPe_ALA<-na.omit(LiPe_ALA)\n",
                "\n",
                "LiPe_pts_ALA <- SpatialPoints(coords = cbind(LiPe_ALA$decimalLongitude, LiPe_ALA$decimalLatitude),CRS(as.character(\"+proj=longlat +datum=WGS84 +no_defs\")) )\n",
                "\n",
                "LiPe_pres_ALA<- rep(1,length(LiPe_ALA$decimalLatitude))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Then create a raster with a value of 1 for each gridcell where a LiPe was recorded\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "LiPe_pres_raster_ALA<-raster::rasterize(LiPe_pts_ALA,base,LiPe_pres_ALA, fun = min, background=0)\n",
                "LiPe_pres_raster2_ALA<-raster::projectRaster(LiPe_pres_raster_ALA,base)\n",
                "LiPe_pres_raster2_ALA<-raster::mask(LiPe_pres_raster2_ALA,base)\n",
                "large_base <- aggregate(base, fact=4)\n",
                "cell_no_ALA<- raster::extract(large_base,LiPe_pts_ALA,cellnumbers=TRUE)\n",
                "LiPe_cells_ALA<- cbind(LiPe_ALA,cell_no_ALA)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "require(dplyr)\n",
                "LiPe_thinned_ALA <- LiPe_cells_ALA %>% \n",
                "  group_by(cells) %>% \n",
                "  slice_sample(n = 1)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "frogs_ALA<-galah_call() %>%\n",
                "  galah_identify(\"Amphibia\")%>%\n",
                "  galah_filter(datasetName != \"FrogID\")%>%\n",
                "  galah_filter(coordinateUncertaintyInMeters < 100)%>%\n",
                "  galah_filter(year>1999)%>%\n",
                "  galah_filter(stateProvince == \"Queensland\")%>%\n",
                "  galah_select(\"datasetName\",\"year\")%>%\n",
                "  atlas_occurrences()\n",
                "\n",
                "frogs_ALA$unique_visit<- paste0(frogs_ALA$decimalLatitude,frogs_ALA$decimalLongitude,frogs_ALA$eventDate)\n",
                "frogs_ALA$visitID <- as.numeric(as.factor(frogs_ALA$unique_visit))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "frogs_ALA2 <- frogs_ALA %>%\n",
                "  group_by(decimalLatitude, decimalLongitude, visitID) %>%\n",
                "  summarise(no_spp = length(unique(scientificName)))\n",
                "\n",
                "frogs_ALA3 <- frogs_ALA2 %>%\n",
                "  group_by(decimalLatitude, decimalLongitude) %>%\n",
                "  summarise(no_visits = length(visitID))\n",
                "\n",
                "frogs_ALA3 <- na.omit(frogs_ALA3)\n",
                "\n",
                "visits_pts_ALA<-SpatialPoints(coords = cbind(frogs_ALA3$decimalLongitude, frogs_ALA3$decimalLatitude),CRS(as.character(\"+proj=longlat +datum=WGS84 +no_defs\")))\n",
                "b1_ALA <- rasterize(visits_pts_ALA, base, frogs_ALA3$no_visits, fun=sum, background=0)\n",
                "\n",
                "bb_ALA <- bbox(b1_ALA)\n",
                "visit_locations_ALA<- raster::extract(b1_ALA, visits_pts_ALA, cellnumbers=TRUE)\n",
                "visit_locations2_ALA <- as.data.frame(na.omit(visit_locations_ALA))\n",
                "cellID_ALA <- unique(visit_locations2_ALA$cells)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "xy_visits_ALA <- raster::xyFromCell(b1_ALA,cell = cellID_ALA)\n",
                "\n",
                "cellStats(b1_ALA ,\"max\")\n",
                "m <- c(0, 2.9, 0,  2.9, 880, 1)\n",
                "reclass <- matrix(m, ncol= 3, byrow= TRUE)\n",
                "rc_ALA <- reclassify(b1_ALA, reclass)\n",
                "\n",
                "visits_3or_more_ALA <- mask(rc_ALA,base)\n",
                "\n",
                "Zero_LiPe_ALA <- visits_3or_more_ALA - LiPe_pres_raster2_ALA\n",
                "\n",
                "freq(Zero_LiPe_ALA)\n",
                "\n",
                "m <- c(-2, 0.1, 0,  0.1, 2, 1)\n",
                "reclass2 <- matrix(m, ncol= 3, byrow= TRUE)\n",
                "rc2_ALA <- reclassify(Zero_LiPe_ALA, reclass2)\n",
                "Zero_LiPe2_ALA<-mask(rc2_ALA,base)\n",
                "freq(Zero_LiPe2_ALA)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# extract the cell numbers from the 0 grid where the value ==1\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cell_vals_0_ALA<-Which(Zero_LiPe2_ALA ==1,cells=TRUE)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "# these are the lat / longs for locations where at least three surveys were done, but zero LiPe were detected - these are our pseudo absences\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "xy_zero_LiPe_ALA <- xyFromCell(Zero_LiPe2_ALA,cell = cell_vals_0_ALA)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#plot the absence locations\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot(base)\n",
                "points(xy_zero_LiPe_ALA, pch=20,cex=0.2)\n",
                "xy_zero_LiPe_ALA <- as.data.frame(xy_zero_LiPe_ALA)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Now lets turn our presence and absence points into one dataset\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "head(LiPe_thinned_ALA)\n",
                "\n",
                "ALA_preds1 <- as.data.frame(cbind(Long = LiPe_thinned_ALA$decimalLongitude, Lat = LiPe_thinned_ALA$decimalLatitude,pres = 1))\n",
                "ALA_preds2 <- as.data.frame(cbind(Long = xy_zero_LiPe_ALA$x, Lat = xy_zero_LiPe_ALA$y,pres = 0))\n",
                "ALA_preds <- rbind(ALA_preds1,ALA_preds2)\n",
                "\n",
                "x_a<- ALA_preds$Long\n",
                "y_a<-ALA_preds$Lat\n",
                "xy_a<-cbind(x_a,y_a)\n",
                "xy.sp_a<-SpatialPoints(xy_a)\n",
                "crs(xy.sp_a) <- crs(LiPe_predictors)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## now we just extract the 1's & 0's using our lat longs from the new ALA data \n",
                "# extracted from the same thresholded brt predictions from above\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "predicted_a <- raster::extract(rc_brt,xy.sp_a)\n",
                "\n",
                "test2 <- as.data.frame(cbind(predicted = predicted_a, reference = ALA_preds$pres))\n",
                "\n",
                "test2$reference <- factor(test2$reference, levels = c(\"1\",\"0\"))\n",
                "test2$predicted <- factor(test2$predicted, levels = c(\"1\",\"0\"))\n",
                "\n",
                "conf_matrix2 <- confusionMatrix(test2$predicted,test2$reference)\n",
                "conf_matrix2\n",
                "\n",
                "TP2 <- conf_matrix2$table[1,1]\n",
                "FP2 <- conf_matrix2$table[1,2]\n",
                "FN2 <- conf_matrix2$table[2,1]\n",
                "TN2 <- conf_matrix2$table[2,2]\n",
                "\n",
                "FPR2 <- FP2/(FP2 + TN2)\n",
                "FNR2 <- FN2/(FN2 + TP2)\n",
                "TPR2 <- TP2/(TP2 + FN2)\n",
                "TNR2 <- TN2/(TN2 + FP2)\n",
                "\n",
                "TSS2 <- TPR2 + TNR2 - 1  \n",
                "TSS2 # notice this is a big drop from our original TSS statistic\n",
                "TSS\n",
                "\n",
                "Precision2 <- TP2 / (TP2 + FP2)\n",
                "Recall2 <- TP2 / (TP2 + FN2)\n",
                "F1_b <- 2*((Precision2*Recall2)/(Precision2+Recall2))\n",
                "F1_b # notice this is a very slight drop from our original F1 statsitic\n",
                "F1\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# When we used data to test the model that was not associated with\n",
                "# the FrogID project, TSS, accuracy, & precision scores all fell markedly\n",
                "# Encouragingly the F1 score did not fall that much, and as a user\n",
                "# you will need to decidd on what levels of accuracy in your\n",
                "# confusion matrix are good enough for the intended use of the model\n",
                "\n",
                "# If I was looking to predict well in order to select what reserves\n",
                "# to make for this frog, I would want better performance.\n",
                "\n",
                "# The first step I would take to improve this model, would be to select\n",
                "# pseudo_absence locations at only those locations where similarly\n",
                "# distributed frogs were seen but our target species was not seen\n",
                "# on three visits. Our psuedo absence points are still including\n",
                "# places in the arid interior where this species would never occur.\n",
                "\n",
                "# Second, as mentioned before, I would also look for better freshwater\n",
                "# wetland layers, perhaps look at how often an area is wet over the last\n",
                "# decoade.\n",
                "\n",
                "# OTHER places to learn how to generate SDMs in R\n",
                "# http://www.earthskysea.org/best-practices-in-species-distribution-modeling-a-workshop-in-r/\n",
                "# a series of lectures on SDMs https://www.youtube.com/watch?v=obuMW5NAtJE \n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "R",
            "langauge": "R",
            "name": "ir"
        },
        "language_info": {
            "codemirror_mode": "r",
            "file_extension": ".r",
            "mimetype": "text/x-r-source",
            "name": "R",
            "pygments_lexer": "r",
            "version": "3.4.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
