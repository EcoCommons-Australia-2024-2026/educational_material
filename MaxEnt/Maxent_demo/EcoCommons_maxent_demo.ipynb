{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b535379",
   "metadata": {},
   "source": [
    "# EcoCommons Notebook: MaxEnt demonstration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98b89dbc-a16d-4ddb-b590-3c053ed91f24",
   "metadata": {},
   "source": [
    "---\n",
    "**Author details:** EcoCommons Platform   \n",
    "**Contact details:** comms@ecocommons.org.au  \n",
    "**Date:** April 2023    \n",
    "**Copyright statement:** This script is the product of EcoCommons platform.   \n",
    "                      Please refer to the <a href=\"https://www.ecocommons.org.au/\">EcoCommons website</a> for more details.\n",
    "\n",
    "  \n",
    "**Script and data info**:&nbsp;   \n",
    " In this notebook, you will run a Maximum Entropy Modeling (MaxeEnt) to predict \n",
    " occurrences by finding the most uniform distribution within the limits of\n",
    " the predictor variables. Maxent is an open-source software created by Phillips and collaborators. More info can be found on <a href=\"https://biodiversityinformatics.amnh.org/open_source/maxent/\">the MaxEnt website.</a>  \n",
    "\n",
    "For those of you new to R, find tips on how to get started <a href=\"https://datacarpentry.org/R-ecology-lesson/\">can be found here</a>.\n",
    "\n",
    "\n",
    "**In this example you will:**\n",
    "   1. Set up your working environment\n",
    "   2. Import and clean occurrence data\n",
    "   3. Import bioclimatic variables data from 'netCDF' files\n",
    "   4. Train a MaxEnt model    \n",
    "   \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3d3af8-866b-431c-8b1b-98402a94c0c5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Load packages that are included in the R environment\n",
    "library(dismo)\n",
    "library(jpeg)\n",
    "library(maps)\n",
    "library(raster)\n",
    "library(rasterVis)\n",
    "library(readxl)\n",
    "library(rgbif)\n",
    "library(rgeos)\n",
    "library(rJava)\n",
    "library(sp)\n",
    "library(svMisc)\n",
    "library(rgdal)\n",
    "library(terra)\n",
    "library(tidyr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a32a0638-dddb-45e8-852a-202d30318d3b",
   "metadata": {},
   "source": [
    "- Tip: you can create a personal library for installing packages that will persist between sessions\n",
    "- You only need to create the lib directory once, but each new session you may need to set `.libPaths()` again to load previously installed packages. \n",
    "- Warning: Packages you install into the default library path will not persist between sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c959ecb-2f15-4c06-a5c9-fbde1ec1dc57",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Check the default library paths\n",
    ".libPaths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc57f6b0-ba87-4c83-9a33-01cbe7f5fa50",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create a personal library in your chosen location or under the current working directory\n",
    "dir.create(\"./lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4be06a2-30c4-4bc3-9b51-7e63c6630c23",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Prepend the path to your personal library to .libPaths\n",
    "# This will add your library path (which will be the default path for installing new packages)\n",
    "# But also keep the default R environment path (to `library` existing packages)\n",
    ".libPaths(c(\"./lib\", .libPaths()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f778873-d359-4d29-8937-8a7fbb16ad47",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "install.packages(\"ncdf4\")\n",
    "library(ncdf4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28df5a8e",
   "metadata": {},
   "source": [
    "# 1. Set up your environment\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24b39d2",
   "metadata": {},
   "source": [
    "We will work inside the current directory of this example notebook. A folder for `data` already exists, but we will create an `output` folder as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d405881e-bc9a-47e6-b294-93a02f6c413a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "dir.create(\"./output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa57d50",
   "metadata": {},
   "source": [
    "Check if the MaxEnt `.jar` file is installed and and available in our environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8185c3e6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "jar <- paste(system.file(package = \"dismo\"), \"/java/maxent.jar\", sep = '') \n",
    "if (file.exists(jar)) {\n",
    "  cat(\"MaxEnt is available.\")\n",
    "  } else {\n",
    "    cat('MaxEnt is not available!')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76a2853",
   "metadata": {},
   "source": [
    "# 2. Import and filter occurrence data\n",
    "---\n",
    "- We will download occurrence records of the frog *Litoria fallax* (Eastern Dwarf Tree Frog), from the GBIF database.\n",
    "- Warning: setting a high limit here can run slowly. So for this example, we limit the query to 500 records.\n",
    "- For large queries, we recommend downloading directly from GBIF, or using the `occ_download*()` functions which are more appropriate for larger requests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74df2efd",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Select your species\n",
    "my_species <- c(\"Litoria fallax\")\n",
    "\n",
    "# Download GBIF occurrence data\n",
    "Litoria_fallax_GBIF_raw <- rgbif:: occ_data(scientificName = my_species,\n",
    "                                            hasCoordinate  = TRUE,\n",
    "                                            limit          = 500) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2fe5e9",
   "metadata": {},
   "source": [
    "Get the information needed to cite this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0344b67b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Return a list of citations for the downloaded GBIF data: \n",
    "citations <- rgbif::gbif_citation(Litoria_fallax_GBIF_raw)\n",
    "\n",
    "# Example of a citation:\n",
    "print(citations[[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6095123c",
   "metadata": {},
   "source": [
    "- Get familiar with the data, and check how the data is organized using `str()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de2de34",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "str(Litoria_fallax_GBIF_raw, list.len = 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a77a5e0",
   "metadata": {},
   "source": [
    "- Explore the `$data` element, which contains the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734ef20c-4c00-4291-8bec-c7316dad7958",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "View(head(Litoria_fallax_GBIF_raw$data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249b0e13-1a12-4b01-b7a9-df728f6fc659",
   "metadata": {},
   "source": [
    "- Select columns needed for mapping and cleaning the occurrence data. \n",
    "- This is just an example of columns that you could select.\n",
    "- We will also filter the records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd7707d-fb36-4c62-ad0a-400dbb3d09f0",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Select columns, and return a `tibble` with only unique rows.\n",
    "litoria_fallax <- unique(tibble::as_tibble(Litoria_fallax_GBIF_raw$data [ , c(\"decimalLongitude\", \"decimalLatitude\",\n",
    "                                                     \"individualCount\", \"species\", \"year\",\n",
    "                                                     \"month\", \"country\", \"occurrenceStatus\",\n",
    "                                                     \"coordinateUncertaintyInMeters\", \"datasetName\",\n",
    "                                                     \"datasetKey\")]))\n",
    "\n",
    "cat(\"- There are\", nrow(litoria_fallax), \"unique occurrence records in the tibble.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5736d4-2a5b-4947-a30e-75050a6ebdad",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# You could subset by a chosen dataset\n",
    "litoria_fallax <- litoria_fallax[litoria_fallax$datasetName == \"iNaturalist research-grade observations\",]\n",
    "# Include only records with a particualary uncertainty\n",
    "litoria_fallax <- litoria_fallax[litoria_fallax$coordinateUncertaintyInMeters < 200,]\n",
    "# Drop NAs\n",
    "litoria_fallax <- litoria_fallax[!is.na(litoria_fallax$datasetName), ]\n",
    "\n",
    "cat(\"- There are now\", nrow(litoria_fallax), \"occurrence records in the tibble after filtering.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3329d6e4-0dcf-468b-a6be-2332e0fc3062",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "View(head(litoria_fallax))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822a6baa-8269-4bff-998c-9883e93238f2",
   "metadata": {},
   "source": [
    "- We can export the `tibble` as a `.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd8598d-c107-4ce1-a77b-c314d536a362",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "write.csv(litoria_fallax, paste0(getwd(),\"/data/Litoria_fallax_filtered.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e151bc-9db9-4f48-844a-c1b83dad76e7",
   "metadata": {},
   "source": [
    "### Map the occurrence data  \n",
    "When downloading data from big datasets, some records are likely to be centroids of(relatively large) grid cells on which particular surveys were based. You can notice them when distribution records are too regularly spaced to be exact locations of species sightings. When it happens, remember to adjust the spatial resolution of your analysis accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3ff9fb-bcae-4099-919d-51010eaefd82",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# NOTE: added cex (point size) and col so the records are easier to see\n",
    "map(\"world\", xlim = range(litoria_fallax$decimalLongitude),\n",
    "    ylim = range(litoria_fallax$decimalLatitude))  \n",
    "points(litoria_fallax[ , c(\"decimalLongitude\", \"decimalLatitude\")], pch = \".\", cex = 3, col = \"blue\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338cb650-7c15-47ce-927c-ddb1a0670746",
   "metadata": {},
   "source": [
    "# 3. Load and process the bioclimatic data\n",
    "---\n",
    "\n",
    "It is example, we will be using data from a netCDF file, obtained from \"TerraClimate\", a dataset of monthly climate and climatic water balance for global terrestrial surfaces from 1958-2019. We decided to include four climatic variables (maximum and minimum temperature, rainfall and soil cover - called \"tmax\", \"tmin\", \"ppt\" and \"soil\", respectively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a138c1e1-bd04-45bc-aefb-fc8bee64f7c4",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Read NetCDF data file of predictors\n",
    "file <- \"~/educational_material/Maxent_example/data/Terraclim_EY_E_Aus_orig.nc\"\n",
    "var_names <- c(\"tmax\", \"tmin\", \"ppt\", \"soil\")  \n",
    "\n",
    "# Visualise one of the variables (tmax)\n",
    "plot(raster::brick(file, varname = \"tmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d91dfd8-30cc-4cb0-b303-b3df3f47ff54",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Save a CDF file of the mean values for each of the variables, in your directory folder\n",
    "for (var_name in var_names) {\n",
    "  \n",
    "  var_brick <- raster::brick(file, varname = var_name)\n",
    "  var_mean  <- mean(var_brick)\n",
    "  \n",
    "  raster::writeRaster(x         = var_mean, \n",
    "                      filename  = paste0(\"./data/\",var_name, \"_mean\"),\n",
    "                      overwrite = TRUE, \n",
    "                      format    = 'CDF')\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70b0de3-6990-4b5a-9418-d528ea657a4f",
   "metadata": {},
   "source": [
    "Stack the predictors together and rename them. Plot to see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd2d8f3-14a4-4d59-a7cd-13ab9c321466",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "mean_files <- list.files(\"./data\", pattern = \"_mean.nc\", full.names = TRUE)\n",
    "predictors <- raster::stack(mean_files)\n",
    "names(predictors) <- c('Rain_mean', 'Soil_mean', 'MXtemp_mean', 'MNtemp_mean')\n",
    "plot(predictors)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b0bacbd3-79d0-45f2-808d-b0f21ed2a492",
   "metadata": {},
   "source": [
    "Create a spatial points layer with the species distribution points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c29eaa6-b129-4f0c-b964-ddfecd804af8",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "xy_fallax <- litoria_fallax[, c(\"decimalLongitude\", \"decimalLatitude\")]\n",
    "colnames(xy_fallax) <- c(\"x\", \"y\")\n",
    "xy_fallax_sp <- sp::SpatialPoints(coords = xy_fallax, proj4string= CRS(\"+proj=longlat +datum=WGS84 +no_defs\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1512aaa-6249-4987-a5c7-b2b8a04700b0",
   "metadata": {},
   "source": [
    "Remove distribution records that are outside of your area of interest and plot to see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64927e6-be84-4cde-a3bb-aeb121c63114",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "xy_fallax_sp <- raster::crop(xy_fallax_sp, predictors[[1]])\n",
    "\n",
    "plot(predictors[[1]])\n",
    "points(xy_fallax_sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f11e9c7-dc32-4d3c-a1b1-f344922600ec",
   "metadata": {},
   "source": [
    "# 4. Run a MaxEnt model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b914f779-715c-4b37-8aab-8f01739b29a7",
   "metadata": {},
   "source": [
    "### Prepare data and fit model\n",
    "\n",
    "First, create training and test points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ab014b-7437-4559-a1f6-d274e8a7488c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "group <- dismo::kfold(xy_fallax_sp, k = 5)\n",
    "pres_test  <- xy_fallax_sp[group == 1, ]  # 20% of data sample for testing\n",
    "pres_train <- xy_fallax_sp[group != 1, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d7b0e9-4378-4e3f-a426-2fd835a695e4",
   "metadata": {},
   "source": [
    "Set the background points and check NAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbccc7e7-c4e9-4f10-9d3a-1ebe3efa24df",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "backg <- dismo::randomPoints(mask = predictors, n = 1000)\n",
    "colnames(backg) <- c(\"lon\", \"lat\")\n",
    "\n",
    "# check the number of NAs\n",
    "x <- raster::extract(predictors, pres_train) \n",
    "y <- na.omit(x)\n",
    "na_count <- length(y)/length(x)  # need to be 0.5 or more\n",
    "na_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e85990c-f98d-404b-9e84-cf0d971bfab2",
   "metadata": {},
   "source": [
    "### Set the various Maxent arguments\n",
    "\n",
    "A full list of the available arguments are at the end of the notebook.  Other things to consider, are adding a bias layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316872ed-e3ec-4446-ad7d-a400b8074da1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "maxent_args <- c(\"removeduplicates=TRUE\",\"jackknife=TRUE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cfeeba-17a1-4f89-999c-5b87e256d1f5",
   "metadata": {},
   "source": [
    "### Run the model\n",
    "\n",
    "- There are different ways to run MaxEnt in R. We choose to use the 'dismo' package.\n",
    "- The outputs will be saved in the `output` folder of the current working directory\n",
    "- This will include the MaxEnt `.html` summary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7598911-de5c-448d-a828-3aacc2f7512d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "basic_maxent<- dismo::maxent(predictors,\n",
    "                             pres_train,\n",
    "                             path = \"./output\",\n",
    "                             args = maxent_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24246c6a-b547-4112-81ad-77975bfdc46d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "plot(basic_maxent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a78941-84aa-4920-b830-b7e03760e94d",
   "metadata": {},
   "source": [
    "Create a RasterLayer with the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4a3901-f690-4b19-a271-110bd764c33f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "map_predictions <- dismo::predict(basic_maxent, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd49012-8a63-4f50-9885-efd349ec82a0",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "plot(map_predictions)\n",
    "points(pres_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a932b4-14e0-4ae9-8f9b-d6aa23a01927",
   "metadata": {},
   "source": [
    "Use the 'evaluate' function on 'dismo' package to see some key results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51049f81-59c6-4bd7-ba97-caf7d56f6f11",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_model <- dismo::evaluate(pres_train, pres_test, basic_maxent, predictors)\n",
    "evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198fa85c-cab9-4cd2-b01d-a8f1d90076e9",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_model@auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272ea3ea-2bf1-414a-8d4c-eb81826670b9",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Save the prediction plot with training points as a `jpeg`\n",
    "jpeg(\"./output/max_prediction.jpeg\")\n",
    "plot(map_predictions)\n",
    "points(pres_train)\n",
    "dev.off()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9183d023-cd68-4f80-9b46-f9914c6da315",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Save the prediction in an `asc` file\n",
    "\n",
    "raster::writeRaster(map_predictions,\n",
    "                    filename  = \"./output/Litoria_fallax_pred.asc\",\n",
    "                    format    = \"ascii\",\n",
    "                    overwrite = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2a9be7-7368-42a8-99fe-e2a4557b703d",
   "metadata": {},
   "source": [
    "Find a threshold (cut-off) to transform model predictions probabilities to a binary score (presence or absence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94b4acd-df9d-432f-bad1-75b2446a564e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "threshold_model <- dismo::threshold(evaluate_model, 'spec_sens')\n",
    "threshold_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3835226a-b8f1-4a88-bcc5-b36529707096",
   "metadata": {},
   "source": [
    "Now, it is time to reclasify the values of the raster object. This is step is OPTIONAL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8835e756-7daf-4ff6-8f71-36c29a088bc0",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "m <- c(0, threshold_model, 0,  threshold_model, 1, 1)\n",
    "reclass <- matrix(m, ncol = 3, byrow = TRUE)\n",
    "rc <- raster::reclassify(map_predictions, reclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d9654-100a-4ad7-9161-b1e346dd6b81",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "jpeg(\"./output/pres_absence_map.jpeg\")\n",
    "plot(rc, main = 'presence/absence')\n",
    "points(pres_train, pch = '+')\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a4f5ce-3b18-4203-9607-ee627a015df5",
   "metadata": {},
   "source": [
    "Generate response plots, single variable response curves for the model you run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8fc31a-f685-40b1-8730-161b8aa747b1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "dismo::response(basic_maxent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fdb601-afb4-45a9-aa2a-b36f9080cad5",
   "metadata": {},
   "source": [
    "- Create a data frame with the evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a7e047-2a43-4e8a-abd7-fadc5e49e5f6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "myspecies <- c(\"Litoria fallax\")\n",
    "cor <- unname(evaluate_model@cor)\n",
    "test_data_results <- as.data.frame(list(myspecies,\n",
    "                                        evaluate_model@np,\n",
    "                                        evaluate_model@na,\n",
    "                                        evaluate_model@auc,\n",
    "                                        cor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9744c0de-4d0d-4d4d-af2d-df875b817930",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "colnames(test_data_results) <- c(\"species\", \"presences\", \"absences\", \"AUC\", \"cor\")\n",
    "test_data_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c14cad8-2bd3-4bd5-8d2c-8852488e24d2",
   "metadata": {},
   "source": [
    "Another option to visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa004331-2b04-45fc-922b-65e21f3891f7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "basic_maxent@results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d887d5-3d40-4288-abd4-fb0f839bd3b8",
   "metadata": {},
   "source": [
    "# 5. List of other MaxEnt arguments you could use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9f0f11-391d-4888-bac7-68c664cf6131",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "maxent_args <- c(\n",
    "  \n",
    "  #duplicate records\n",
    "  'removeduplicates=TRUE', #remove duplicate presence records. If environmental data are in grids, duplicates are records in the same grid cell, otherwise, duplicates are records with identical coordinates.\n",
    "  \n",
    "  #background records\n",
    "  'maximumbackground=10000', #if the number of background points/grid cells is larger than this number, then this number of cells is chosen randomly for background points.\n",
    "  'addsamplestobackground=TRUE', #add to the background any sample for which has a combination of environmental values that isn't already present in the background\n",
    "  'addallsamplestobackground=FALSE', #add all samples to the background, even if they have combinations of environmental values that are already present in the background\n",
    "  \n",
    "  #missing data\n",
    "  'allowpartialdata=FALSE', #during model training, allow use of samples that have nodata values for one or more environmental variables\n",
    "  \n",
    "  #variable importance\n",
    "  'jackknife=TRUE', #NB: default=FALSE; measure importance of each environmental variable by training with each environmental variable first omitted, then used in isolation.\n",
    "  \n",
    "  #random seed\n",
    "  'randomseed=FALSE', #if selected, a different random seed will be used for each run, so a different random test/train partition will be made and a different random subset of the background will be used, if applicable.\n",
    "  \n",
    "  #prevalence\n",
    "  'defaultprevalence=0.5', #default prevalence of the species: probability of presence at ordinary occurrence points. See Elith et al. Diversity and Distributions, 2011 for details\n",
    "  \n",
    "  #train/test settings\n",
    "  'randomtestpoints=0', #percentage of presence localities to be randomly set aside as test points, used to compute AUC, omission, etc.\n",
    "  'replicates=1', #number of replicate runs to do when cross-validating, bootstrapping or doing sampling with replacement runs.\n",
    "  'replicatetype=crossvalidate', #if replicates > 1, do multiple runs of this type: \n",
    "      #crossvalidate: samples divided into replicates fods; each fold in turn used for test data\n",
    "      #bootstrap: replicate sample sets chosen by sampling with replacement\n",
    "      #subsample: replicate sample sets chosen by removing random test percentage without replacement to be used for evaluation\n",
    "  'maximumiterations=500', #stop training after this many iterations of the optimization algorithm\n",
    "  'convergencethreshold=0.00001', #stop training when the drop in log loss per iteration drops below this number \n",
    "  \n",
    "  #feature selection\n",
    "  'autofeature=TRUE', #automatically select which feature classes to use, based on number of training samples\n",
    "  'linear=TRUE', #allow linear features to be used\n",
    "  'quadratic=TRUE', #allow quadratic features to be used\n",
    "  'product=TRUE', #allow product features to be used\n",
    "  'threshold=TRUE', #allow threshold features to be used\n",
    "  'hinge=TRUE', #allow hinge features to be used\n",
    "  \n",
    "  #feature settings\n",
    "  'lq2lqptthreshold=80', #number of samples at which product and threshold features start being used\n",
    "  'l2lqthreshold=10', #number of samples at which quadratic features start being used\n",
    "  'hingethreshold=15', #number of samples at which hinge features start being used\n",
    "  \n",
    "  #regularization settings\n",
    "  'betamultiplier=1', #multiply all automatic regularization parameters by this number. A higher number gives a more spread-out distribution.\n",
    "  'beta_threshold=-1', #regularization parameter to be applied to all threshold features; negative value enables automatic setting\n",
    "  'beta_categorical=-1', #regularization parameter to be applied to all categorical features; negative value enables automatic setting\n",
    "  'beta_lqp=-1', #regularization parameter to be applied to all linear, quadratic and product features; negative value enables automatic setting\n",
    "  'beta_hinge=-1', #regularization parameter to be applied to all hinge features; negative value enables automatic setting\n",
    "  \n",
    "  #outputs - NB. These are not shown in the UI, so unable to be changed by user\n",
    "  \n",
    "  'responsecurves=TRUE', #NB. default=FALSE; create graphs showing how predicted relative probability of occurrence depends on the value of each environmental variable\n",
    "  'responsecurvesexponent=FALSE', #instead of showing the logistic value for the y axis in response curves, show the exponent (a linear combination of features).\n",
    "  'pictures=TRUE', #create a .png image for each output grid\n",
    "  'outputformat=raw', #representation of probabilities used in writing output grids, see Help for details\n",
    "  'writeclampgrid=TRUE', #write a grid that shows the spatial distribution of clamping. At each point, the value is the absolute difference between prediction values with and without clamping.\n",
    "  'writemess=TRUE', #a multidimensional environmental similarity surface (MESS) shows where novel climate conditions exist in the projection layers. The analysis shows both the degree of novelness and the variable that is most out of range at each point.\n",
    "  'writeplotdata=FALSE', #write output files containing the data used to make response curves, for import into external plotting software.\n",
    "  'outputgrids=TRUE', #write output grids. Turning this off when doing replicate runs causes only the summary grids (average, std, deviation, etc) to be written, not those for the individual runs.\n",
    "  'plots=TRUE', #write various plots for inclusion in .html output\n",
    "  'logfile=maxent.log', #file name to be used for writing debugging information about a run in output directory\n",
    "  #'applythresholdrule=Fixed cumulative value 1', #apply a threshold rule, generating a binary outputgrid in addition to the regular prediction grid. Use the full name of the threshold rule in Maxent's html output as the argument. For example 'applyThresholdRule=Fixed cumulative value 1'.\n",
    "  'logscale=TRUE', #if selected, all pictures of models will use a logarithmic scale for color-coding\n",
    "  'writebackgroundpredictions=FALSE', #write .csv file with predictions at background points\n",
    "  'fadebyclamping=FALSE', #reduce prediction at each point in projections by the difference between clamped and non-clamped output at that point\n",
    "\n",
    "  #projection settings NB. These are not shown in the UI, so unable to be changed by user\n",
    "  \n",
    "  'extrapolate=TRUE', #predict to regions of environmental space outside the limits encountered during training\n",
    "  'doclamp=TRUE' #apply clamping when projecting\n",
    "  \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
